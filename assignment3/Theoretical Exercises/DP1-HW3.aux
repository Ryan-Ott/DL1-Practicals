\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Generative Part of the VAE}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Steps needed to sample an image from the decoder}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Why Monte-Carlo sampling is inefficient for VAE training}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Why ELBO is a lower bound on the log-likelihood}{1}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}What happens to left hand terms when when the lower bound is pushed up}{1}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Why are the names reconstruction loss and regularization loss appropriate}{1}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Why does sampling prevent gradient computation and how does reparameterization solve this}{1}{subsection.1.6}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{D41D8CD98F00B204E9800998ECF8427E}
\gdef \@abspage@last{2}
